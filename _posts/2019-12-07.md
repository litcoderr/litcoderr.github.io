---
layout: post
title: 모두콘 2019 생각의 흐름 노트필기
tags: [ML, Conference]
---

# 주머니 속 AI (Mobile On-Device Deep Learning)
> time : 10:55 - 12:40
## Mobile GPU Serving
Speaker: Naver Clova AI Vision 이혜민 님
- Knowing the platform is important
#### Advantages
- Free from privacy issues
#### Overcomming CPU Fallback issue
- Use GPGPU with OpenGL GL Shader
#### GPU Optimization Problems / Solutions
- Reshaping Multi Dimensional Tensor ?? Why.. How
- PHWD4 Layout
- Optimizing Work Group for different types of GPU
#### For Machine Learning Engineers some tips
- Remove reshape
- input tensor depth 를 4의 배수로
- RGBA 를 굳이 3 channel로 만들지 말고 그냥 카메라 단에서 바로 GPU에 태울 수 있음
- Use GPU Delegator
- Use DSP(Digital Signal Processor) if needed

## Lightweight Deep Learning Roadmap
Speaker : 모두연 MOT 신정아
#### Let's run BERT on Mobile Device!!
- Find Smaller Model : Neural Architecture Search(NetAdapt MNasNet)
- Use ALBERT (from Google)
- Model Compression (Weight Pruning, Quantization, Binarization, Weight Sharing, Knowledge Distillation, Transfer Learning)
#### Weight Pruning
- 필요 없는 weight 는 0으로 처리 -> Question: 그렇다고 모델 크기가 줄어드나? 연산량이 주는거 아닌가?
#### Quantization
- float32 -> uint8

# 언어 속 AI (NLP)
> time : 13:40 - 15:25
## Embedding, the way to improve NLP model performance
Speaker: Naver Chatbot Model 이기창
- Use sentence based encoding (ELMo BERT ..)
 
## Recap
- 요즘 시퀀스 모델을 죽 보고 있는데 상당히 좋은 키워드들을 많이 건짐
- 오랜만에 지인분들을 만나뵐 수 있었음. Great

